---
title: "Main exploratory analysis"
author: "Luis"
date: "03/2022"
output: html_document
---

To assess the influence of individual data points with respect to the “full” model we calculated a difference in beta values (DFBETA) removed data points one at a time and reran the model with each point excluded once (Besley et al. 1980). The change in the consequent beta estimates of the “full” model were inspected to check that no single data point largely altered their values. If highly influential data points were found, we would consider whether the model is misspecified (i.e. missing an important control). Data would only be removed in the circumstance that we can clearly demonstrate there was an error in the data collection, or data cleaning pipeline that led to implausible values. In the case that the model with respect to the data is unstable, the validity of any significant results from the beta regressions would be highly questionable. The presence of multicollinearity was evaluated with variance inflation factors (VIF; Fox & Weisberg, 2019). A VIF value of >2 would indicate evidence of multicollinearity and we would consider keeping only one of the variables with high VIF values. 

A dispersion parameter greater than 1 can be considered a problem. In such a case, the dispersion of the data can be modeled individually to account for overdispersion, or in extreme cases, the estimates can be recalculated and scaled by the square root of the dispersion parameter. If it is not possible to address overdispersion, the model estimates would be considered unreliable and must be interpreted with caution. 

Full Model:
daily_percentile ~ z.IDS_pref * CDI.agerange + z.IDS_pref * method + z.IDS_pref * nae + gender + (1 |labid) + (1 | subid_unique)
Null Model:
daily_percentile ~ CDI.agerange + method + nae + gender + (1 | labid) + (1 | subid_unique)

```{r setup, echo = FALSE, include = FALSE}
knitr::opts_chunk$set(echo = FALSE, include = FALSE)
```

```{r libraries, echo = FALSE, include = FALSE}
library(dplyr)
library(glmmTMB)
library(ggplot2)
library(lmtest)
library(rstatix)
library(sjPlot)
library(rstudioapi) 
library(performance)
```

```{r preprocessing, echo = TRUE, include = TRUE, warning = FALSE}
rm(list = ls())
# Always start by setting the current directory to the directory of this script file.
setwd(dirname(getActiveDocumentContext()$path))
source("glmmTMB_stability.r")
source("diagnostic_fcns.r")
# Load data from a .txt file
imported <- read.delim("data/cdi_percentile/percentiles_manybabies_cdi.txt", stringsAsFactors = TRUE, header = TRUE) 

# Data set that will be used for the analyses.
data <- data.frame(daily_percentile = imported$daily_percentile, IDS_pref = imported$IDS_pref, age_mo = imported$age_mo, CDI.agedays = imported$CDI.agedays, method = imported$method, gender = imported$gender, labid = imported$labid, subid_unique = imported$subid_unique, nae = imported$nae, vocab_nwords = imported$vocab_nwords, CDI.agerange = imported$CDI.agerange)

# These are only used to understand the distribution of each variable.
hist(data$daily_percentile, breaks = 100)
hist(data$IDS_pref)
hist(data$age_mo)
plot(data$method)
plot(data$gender)
plot(data$labid)
plot(data$subid_unique)
plot(table(data$nae))

# Ensuring the value is a factor because it is a categorical variable.
data$CDI.agerange <- as.factor(data$CDI.agerange)

# Ensuring the response variable is between 0 and 1, as is required for a beta error model.
data$daily_percentile[data$daily_percentile == 0] <- 1

if(any(data$daily_percentile > 1))
{
  data$daily_percentile <- data$daily_percentile / 100
}

#get the data with all NA values removed.
full.fe.re <- fe.re.tab(fe.model = "daily_percentile ~ IDS_pref * age_mo + IDS_pref * CDI.agerange + IDS_pref * method + IDS_pref * nae + gender", re = c("labid", "subid_unique"), data = data)
t.data <- full.fe.re$data

#z transformation of the predictors to help with the interpretation of the model.
t.data$z.IDS_pref <- as.vector(scale(t.data$IDS_pref))
t.data$z.age_months <-  as.vector(scale(t.data$age_mo))

#Running the mixed effects model with a beta error distribution for the response variable.
full <- glmmTMB(daily_percentile ~ z.IDS_pref * z.age_months + z.IDS_pref * CDI.agerange + z.IDS_pref * method + z.IDS_pref * nae + gender + (1 |labid) + (1 | subid_unique), family = beta_family(link = "logit"), data = t.data)

#Checking the assumption that variance and the mean are linked. It was met with this model.
overdisp.test(full)

#Best Linear Unbiased Predictors: the estimated deviations of intercepts and slopes from the respective common average, per level of the random effects.
ranef.diagn.plot(full) #The random effects appear normally distributed.

#Test for collinearity between the predictors. There are no signs of collinearity.
coll_model <- lm(daily_percentile ~ z.age_months + z.IDS_pref + CDI.agerange + method + nae + gender, data = t.data)
library(car)
vif(coll_model)

# The same structure as the full model but removes the key variable of interest "IDS_pref" and all its interacting terms.
# This will help control for the multitude of possible models that we could run with this term and if this model is found to be 
# statistically significantly different from the full model, that suggests "IDS_pref" is associated with daily_percentile. 
null <- glmmTMB(daily_percentile ~ z.age_months + CDI.agerange + method + nae + gender + (1 | labid) + (1 | subid_unique), family = beta_family(link = "logit"), data = t.data)

# full - null model comparison reveals that the effect of z.IDS_pref doesn't significantly improve the model fit.
as.data.frame(anova(null, full, test="Chisq"))

full_no_int <- glmmTMB(daily_percentile ~ z.IDS_pref + z.age_months + CDI.agerange + method + nae + gender + (1 |labid) + (1 | subid_unique), family = beta_family(link = "logit"), data = t.data)

overdisp.test(full_no_int)

#Test for stability by dropping levels of the random effects one at a time and comparing the estimates derived from models fitted on the respective subsets with those obtained for the full
# data set. There don't seem to be major issues with the stability of the model coefficients.
# Takes a while to run
# full.stab <- glmmTMB.stab(model.res = full_no_int, para = TRUE, data = t.data)
# table(full.stab$detailed$converged)
# m.stab.plot(full.stab$summary[, -1])

null_no_int <- glmmTMB(daily_percentile ~ z.age_months + CDI.agerange + method + nae + gender + (1 |labid) + (1 | subid_unique), family = beta_family(link = "logit"), data = t.data)

# full - null model comparison reveals that the effect of z.IDS_pref doesn't significantly improve the model fit.
as.data.frame(anova(null_no_int, full_no_int, test="Chisq"))

summary(full)
summary(null)

# computes the conditional and marginal R squared values for the full and null models.
r2_nakagawa(full_no_int)
r2_nakagawa(null_no_int)

performance_rmse(full)
performance_rmse(null)

summary(full_no_int)
summary(null_no_int)

# computes the conditional and marginal R squared values for the full and null models.
r2_nakagawa(full_no_int)
r2_nakagawa(null_no_int)

# Computes the residual mean standard error for both the full and null models.
performance_rmse(full_no_int)
performance_rmse(null_no_int)
```

