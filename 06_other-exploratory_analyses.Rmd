---
title: "MB1 CDI Follow-up Exploratory Analysis"
author: "The ManyBabies Analysis Team"
date: '`r format(Sys.time(), "%a %b %d %X %Y")`'
output: 
  html_document:
    toc: true
    toc_float: true
    number_sections: yes
---

# Introduction

In this script, we are exploring whether using the residual IDS preference model (after controlling for method and IDS test age) as predictors in the mixed-level models will yield similiar results.

The following analysis codes were adapted from 03_confirmatory_analysis.Rmd

First, load libraries and data
```{r setup, message=FALSE, warning=FALSE}
# Library imports, general settings ==============
library(tidyverse) 
library(egg)
library(knitr)
library(lme4)
library(lmerTest)
library(psych)
library(pwr)
# library(brms)
# library(rstan)

theme_set(theme_bw(base_size = 10))
knitr::opts_chunk$set(cache = TRUE)

# Read data ======================================
col_types <- cols(
  labid = col_factor(),
  subid = col_factor(),
  subid_unique = col_factor(),
  CDI.form = col_factor(),
  CDI.nwords = col_integer(),
  CDI.prop = col_number(),
  CDI.agerange = col_factor(),
  CDI.agedays = col_integer(),
  CDI.agemin = col_integer(),
  CDI.agemax = col_integer(),
  vocab_nwords = col_integer(),
  standardized.score.CDI = col_character(),
  standardized.score.CDI.num = col_number(),
  IDS_pref = col_number(),
  language = col_factor(),
  language_zone = col_factor(),
  CDI.error = col_logical(),
  Notes = col_character(),
  trial_order = col_factor(),
  method = col_factor(),
  age_days = col_integer(),
  age_mo = col_number(),
  age_group = col_factor(),
  nae = col_logical(),
  gender = col_factor(),
  second_session = col_logical()
)

data.total <- read_csv("data/02b_processed.csv", col_types = col_types) %>% 
  mutate(subid_long = paste(labid, subid, sep = "_"))

cdi_subid <- data.total %>% 
  select(subid_long)

# Read Mb1 data for reliability check==============
mb1_git <- read_csv("https://github.com/manybabies/mb1-analysis-public/raw/master/processed_data/03_data_diff_main.csv") %>%
select(lab, subid, diff, stimulus_num, method, age_group) %>%
mutate(subid = paste(lab, subid, sep = "_"))

write.csv(mb1_git, "mb1.csv")

# Read in archived MB1 data

mb1 <- read_csv("mb1.csv")
rm(mb1_git)


# Create a dataframe that indicates how many paired trials each infant has in MB1
mb1_num_pair <- mb1 %>% 
  filter(!is.na(diff)) %>% 
  group_by(lab, subid) %>% 
  summarize(n = n())

mb1_excl4 <- mb1_num_pair %>% 
  filter(n >= 4)

mb1_excl6 <- mb1_num_pair %>% 
  filter(n >= 6)

mb1_excl8 <- mb1_num_pair %>% 
  filter(n >= 8)

# Must have data in wide dataframe (one row per participant, observations across columns), rather than long dataframe

mb1_wide_excl2 <- mb1 %>%
  filter(subid %in% cdi_subid$subid_long) %>% 
  filter(!is.na(diff)) %>% # Removes NA values that were causing problems
  pivot_wider(id_cols = c(lab, subid, method, age_group), names_from = stimulus_num, values_from = diff)

mb1_wide_excl4 <- mb1 %>%
  filter(subid %in% mb1_excl4$subid) %>% 
  filter(subid %in% cdi_subid$subid_long) %>% 
  filter(!is.na(diff)) %>% # Removes NA values that were causing problems
  pivot_wider(id_cols = c(lab, subid, method, age_group), names_from = stimulus_num, values_from = diff)
  
mb1_wide_excl6 <- mb1 %>%
  filter(subid %in% mb1_excl6$subid) %>% 
  filter(subid %in% cdi_subid$subid_long) %>% 
  filter(!is.na(diff)) %>% # Removes NA values that were causing problems
  pivot_wider(id_cols = c(lab, subid, method, age_group), names_from = stimulus_num, values_from = diff)

mb1_wide_excl8 <- mb1 %>%
  filter(subid %in% mb1_excl8$subid) %>% 
  filter(subid %in% cdi_subid$subid_long) %>% 
  filter(!is.na(diff)) %>% # Removes NA values that were causing problems
  pivot_wider(id_cols = c(lab, subid, method, age_group), names_from = stimulus_num, values_from = diff)  
  
```

## Contrast Setups

We need `gender` as an effect-coded factor, and `method` as a deviation-coded factor. This is achieved in R by using the `contr.sum()` function with the number of levels for each factor. Notably, when subsetting the NAE and UK samples, only two levels of `method` out of the three in total were left. [NOTE FROM MELANIE: I think you mean just the UK sample? NAE has all three]

```{r contrasts}
# Set contrasts on the total dataset =============
contrasts(data.total$gender) <- contr.sum(2)
contrasts(data.total$method) <- contr.sum(3)
# Create sub-datasets, with contrasts ============
## NAE
data.nae <- data.total %>% subset(language_zone == "NAE") %>% droplevels()
contrasts(data.nae$gender) <- contr.sum(2)
contrasts(data.nae$method) <- contr.sum(3)
## UK
data.uk <- data.total %>% subset(language_zone == "British") %>% droplevels()
contrasts(data.uk$gender) <- contr.sum(2)
contrasts(data.uk$method) <- contr.sum(2)
## Other
data.other <- data.total %>% subset(language_zone == "Other") %>% droplevels()
contrasts(data.other$gender) <- contr.sum(2)
contrasts(data.other$method) <- contr.sum(3)
```

# Descriptive Statistics

We first assess the amount of data we have overall per condition and their shape overall.

```{r desc_total}
data.total %>%
  group_by(language_zone, CDI.agerange, method, gender) %>%
  summarise(N = n(), age = mean(CDI.agedays), sd = sd(CDI.agedays)) %>%
  kable()
```

We then assess the data per lab in terms of sample size and CDI score (vocabulary size, for consistency between language zones).

```{r desc_by_lab}
by_lab <- data.total %>%
  group_by(labid, language_zone, CDI.agerange) %>%
  mutate(tested = n_distinct(subid_unique)) %>%
  select(labid, language_zone, CDI.agerange, tested, vocab_nwords) %>%
  nest(scores = vocab_nwords) %>%
  mutate(model = map(scores, ~ lm(vocab_nwords ~ 1, data = .x)),
         ci = map(model, confint)) %>%
  transmute(tested = tested,
            mean = map_dbl(model, ~ coefficients(.x)[[1]]),
            ci_lower = map_dbl(ci, 1),
            ci_upper = map_dbl(ci, 2)) %>%
  arrange(language_zone) %>%
  rownames_to_column()

# TODO: find a way to group by language zone?
ggplot(by_lab,
       aes(x = labid, colour = language_zone,
           y = mean, ymin = ci_lower, ymax = ci_upper)) + 
  geom_linerange() + 
  geom_point(aes(size = tested)) + 
  facet_grid(cols = vars(CDI.agerange), scales = "free") + coord_flip(ylim = c(0, 500)) +
  xlab("Lab") + ylab("Vocabulary size") +
  scale_colour_brewer(palette = "Dark2", name = "Language zone",
                      breaks = c("British", "NAE", "Other")) +
  scale_size_continuous(name = "N", breaks = function(x) c(min(x), mean(x), max(x))) +
  theme(legend.position = "bottom")
```

# Mixed-Effects Model by Language Zone

Here, we run a mixed-effects model like what the RR stated with a slightly differently approach. Instead of controlling main effect of the method, IDS test age in the model that we predict CDI scores. We would like to create a residuals that control the effects of the "method" and "IDS test age" and create this residuals in the model.

```{r }
# Run models =====================================
## NAE
### First, create the residuals for the IDS preference model
lm_IDS_pref <- lm(IDS_pref ~ method + z_age_months, data = data.nae)

data.nae$lm_IDS_pref_resid <- residuals(lm_IDS_pref)

lmer.full.nae <- lmer(standardized.score.CDI.num ~ CDI.z_age_months +
                        lm_IDS_pref_resid + lm_IDS_pref_resid:CDI.z_age_months +
                        (1 | labid),
                      data = data.nae)

summary(lmer.full.nae)
```


```{r}
## UK
### Create the residuals for the IDS preference model for the UK sample
lm_IDS_pref_UK <- lm(IDS_pref ~ method + z_age_months, data = data.uk)

data.uk$lm_IDS_pref_resid_UK <- residuals(lm_IDS_pref_UK)

lmer.full.uk <- lmer(z_vocab_nwords ~ CDI.z_age_months + gender +
                       lm_IDS_pref_resid_UK + lm_IDS_pref_resid_UK:CDI.z_age_months +
                       (1 | labid),
                     data = data.uk)

summary(lmer.full.uk)

```


## Exploratory picture based on residuals

```{r}
resid_mod <- lm(IDS_pref ~ method + z_age_months, 
                                 data = data.total)

summary(resid_mod)
data.total$ids_resid <- resid(resid_mod)
```

```{r}
hist(data.total$ids_resid)
```

```{r}
ggplot(data.total, 
       aes(x = ids_resid, y = vocab_nwords, col = CDI.agerange)) + 
  geom_point() + 
  geom_smooth(method = "lm") + 
  facet_wrap(~language_zone) + 
  #langcog::theme_mikabr() + 
  #langcog::scale_color_solarized(name = "Age group (months)") + 
  ylab("Number of words produced") + 
  xlab("Age- and Method-residualized IDS preference") + 
  theme(legend.position = "bottom")
```
Just for kicks, let's use IDS preference. 

```{r}
ggplot(data.total, 
       aes(x = IDS_pref, y = vocab_nwords, col = CDI.agerange)) + 
  geom_point() + 
  geom_smooth(method = "lm") + 
  facet_wrap(~language_zone) + 
  #langcog::theme_mikabr() + 
  #langcog::scale_color_solarized(name = "Age group (months)") + 
  ylab("Number of words produced") + 
  xlab("IDS preference") + 
  theme(legend.position = "bottom")
```

# Sensitivity analysis incorporating reliability information
We will compute ICC3k using psych package. In the following, we will examine the reliability in different exclusion criteria. Note that this analysis is not reported in the manuscript, as a related and more powerful analysis using the full MB1 dataset was reported in Byers-Heinlein et al. (2021). Preprint: https://psyarxiv.com/u37fy/ 

```{r}
# Must remove all factor columns (lab, studyid, method, age_group), leaving just matrix of values needed to compute ICC

mb1_excl2_icc <- mb1_wide_excl2 %>%
select(-lab, -subid, -method, -age_group)

```

Compute ICC values and pull out ICC3k.

```{r}
icctable_excl2 <- ICC(mb1_excl2_icc, missing = FALSE, lmer = TRUE) #ICC3k = .124
icc3k_excl2 <- icctable_excl2$results %>% filter(type == "ICC3k") %>% select("ICC") %>% pull() # Use these values, which represent all babies with at least two trials, same as MB1-CDI

# Other values for other exclusion criteria- exploratory/not used (just for informational purposes)

```

Power analysis for ICC
```{r}

# Previous research suggests that CDI test-retest reliability is .86-.90 (Dale et al., 1989, Jahn-Samilo et al., 2001; Simonsen et al., 2014). We will go with .86 to be conservative.
# What power do we have to detect the correlation between CDI and IDS preference, given the reliability of the CDI and the reliability of IDS preference at different exclusion criteria?


# Functions to compute spearman-brown prophecy formula
spearman_brown_obs <- function(r_true, rxx, ryy) {
 r_obs <-  r_true*sqrt(rxx*ryy)
    return(r_obs)
}

spearman_brown_true <- function(r_obs, rxx, ryy) {
  r_true <- r_obs/sqrt(rxx*ryy)
  return(r_true)
}


# Number of infants in each subgroup
n_nae <- length(data.nae$subid)
n_uk <- length(data.uk$subid)


# Observed correlations we can detect at 80% power with sample size of each subgroup
pwr_nae <- round(pwr.r.test(n = n_nae, power = .8)$r,2) # .15
pwr_uk <- round(pwr.r.test(n = n_uk, power = .8)$r,2) # .29


# Applying the spearman-brown prophecy formula, true correlations that can be detected given ICC associated with each exclusion criterion, assuming CDI reliability of .86
spearman_brown_true(pwr_nae, .86, icc3k_excl2) # r = .46
spearman_brown_true(pwr_uk, .86, icc3k_excl2) # r = .89



```



# Daily CDI percentiles

## Reliable languages only

## All languages

# IDS trial-based analyses

## Exclusions based on number of trials completed

Need 280+ babies that have > 4 trial pairs in the best case scenario (in terms of reliability of IDS and CDI and the possible predictive effect of IDS on CDI). Based on a power analysis by Krista Byers-Heinlein.

Reliabilities and results with more completed trial pairs? Comparison table of different results we could get? In this table, number of trials completed, number of infants included, result obtained overall (correlation? handpicked significant effect(s)?).

## Taking all trials

Looking time per trial as a DV.
Looking at CDI, trial number, and trial type (IDS/ADS) as predictors.

Might not be a good pragnatic choice as it is difficult to explain to the reviewers.

# Other exploratory analyses

## CDI reliability

Correlation between 18- and 24-month-old measure per infant. Helps with the power simulations to know what to expect based on our sample size and estimated predictive effect.

